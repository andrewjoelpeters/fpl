{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from tqdm import tqdm #progress bar library -- not necessary, but helpful since some of this is slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I spent a long time cleaning & concatenating data from different seasons until I stumbled upon this:\n",
    "# https://github.com/solpaul/fpl-prediction/blob/master/data/train_v5.csv\n",
    "# this df has data from all seasons since 16-17 by gameweek, with the 19-20 season labeled as 1920, for example, in the \"season\" col\n",
    "# thanks solpaul!\n",
    "\n",
    "# the only thing this dataset is missing is player value on fpl, but from previous analyis, player value wasn't\n",
    "# an effictive predicting feature, so I'm not worried about it for now. Can always merge it later\n",
    "\n",
    "def get_previous_seasons_data():\n",
    "    previous_seasons_data_url = '/Users/andrewpeters/GitHub/fpl/data/external/solpaul-train_v5-311220.csv' #date-code for last time I downloaded this df\n",
    "    previous_seasons_data = pd.read_csv(previous_seasons_data_url, index_col = 0)\n",
    "    \n",
    "    #this dataset has some data from the current (20-21) season, which we don't want\n",
    "    previous_seasons_data = previous_seasons_data[previous_seasons_data.season != 2021]\n",
    "    return previous_seasons_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_data():\n",
    "    #first, pull the ids for all players\n",
    "    url = 'https://fantasy.premierleague.com/api/bootstrap-static/'\n",
    "    r = requests.get(url)\n",
    "    json = r.json()\n",
    "    elements_df = pd.DataFrame(json['elements']) #probably a more efficient way to this than a df\n",
    "    \n",
    "    #using the player ids from elements_df, pull in detailed player info\n",
    "    # I'm going compile two dataframes -- one that shows gw by gw history for each player (this season), and \n",
    "    # another that shows games to be played\n",
    "    history_df = pd.DataFrame()\n",
    "    fixtures_df = pd.DataFrame()\n",
    "\n",
    "    for player in tqdm(elements_df.id):\n",
    "        url = f'https://fantasy.premierleague.com/api/element-summary/{player}/'\n",
    "        r = requests.get(url)\n",
    "        json = r.json()\n",
    "        player_history_df = pd.DataFrame(json['history'])\n",
    "        player_fixtures_df = pd.DataFrame(json['fixtures'])\n",
    "        player_fixtures_df.loc[:, 'element'] = player\n",
    "        history_df = history_df.append(player_history_df)\n",
    "        fixtures_df = fixtures_df.append(player_fixtures_df)\n",
    "    \n",
    "    return history_df, fixtures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_season_df = get_previous_seasons_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 673/673 [01:57<00:00,  5.71it/s]\n"
     ]
    }
   ],
   "source": [
    "current_season_df, unplayed_fixtures_df = get_latest_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump data to /raw folder for safekeeping if api breaks\n",
    "current_season_df.to_pickle('/Users/andrewpeters/GitHub/fpl/data/raw/current_season_df.pkl')\n",
    "unplayed_fixtures_df.to_pickle('/Users/andrewpeters/GitHub/fpl/data/raw/unplayed_fixtures_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_info():\n",
    "    url = 'https://fantasy.premierleague.com/api/bootstrap-static/'\n",
    "    r = requests.get(url)\n",
    "    json = r.json()\n",
    "\n",
    "    #pull player info\n",
    "    elements_df = pd.DataFrame(json['elements'])\n",
    "    elements_df['player'] = elements_df['first_name'] + '_' + elements_df['second_name']\n",
    "    elements_df = elements_df.loc[:, ['id', 'element_type', 'team_code', 'player', 'chance_of_playing_this_round']]\n",
    "    \n",
    "    #merge in team names\n",
    "    teams_df = pd.DataFrame(json['teams'])\n",
    "    elements_df = elements_df.merge(teams_df[['code', 'name']], left_on = 'team_code', right_on='code')\n",
    "    \n",
    "    return elements_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_historical_current_df():\n",
    "\n",
    "    # merge in some of the basic player info from the elements df\n",
    "    merged_current_season_df = current_season_df.merge(elements_df, left_on = 'element', right_on = 'id')\n",
    "    merged_current_season_df = merged_current_season_df.rename(columns={'element_type': 'position',\n",
    "                                     'round': 'gw',\n",
    "                                      'name': 'team',\n",
    "                                      'chance_of_playing_this_round': 'play_proba'\n",
    "                                     })\n",
    "    merged_current_season_df['season'] = 2021\n",
    "    \n",
    "    #add in opp team names\n",
    "    merged_current_season_df = merged_current_season_df.merge(teams_df[['id', 'name']], left_on = 'opponent_team', right_on = 'id')\n",
    "    merged_current_season_df['opponent_team'] = merged_current_season_df['name']\n",
    "\n",
    "    #append the newly merged current season df with the previous season\n",
    "    df = merged_current_season_df.append(previous_season_df)\n",
    "    \n",
    "    #drop columns that only were in one df or the other prior to appending, and that we're not going to use\n",
    "    df = df.drop(columns=['fixture', 'value', 'team_code', 'code', 'relative_market_value_team',\n",
    "            'relative_market_value_opponent_team', 'relative_market_value_team_season',\n",
    "            'relative_market_value_opponent_team_season', 'name'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_df = get_player_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'teams_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5052980b1f06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend_historical_current_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-1eea9a6d22e9>\u001b[0m in \u001b[0;36mappend_historical_current_df\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#add in opp team names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmerged_current_season_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_current_season_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteams_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'opponent_team'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmerged_current_season_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'opponent_team'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_current_season_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'teams_df' is not defined"
     ]
    }
   ],
   "source": [
    "df = append_historical_current_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_unplayed_fixtures():\n",
    "    #only need to keep some columns\n",
    "    fixtures = unplayed_fixtures_df[['element', 'team_h', 'team_a', 'event_name', 'kickoff_time', 'finished', 'is_home']]\n",
    "    \n",
    "    #games far enough in the future don't have a date assigned, not useful\n",
    "    fixtures = fixtures.dropna()\n",
    "    \n",
    "    #helper function for stripping letters from gameweek column\n",
    "    def strip_letters(string):\n",
    "        return re.sub('\\D', '', string)\n",
    "    \n",
    "    # convert 'Gameweek 25' to just '25' (as an int)\n",
    "    fixtures.loc[:, 'gw'] = fixtures.apply(lambda x: strip_letters(x['event_name']), axis=1)\n",
    "    \n",
    "    #bring in player-level info to each unplayed fixture row\n",
    "    fixtures = fixtures.merge(df[['element', 'player', 'position', 'team']], how='left', on='element')\n",
    "    \n",
    "    #the merge causes many duplicates, because each player has many rows in df\n",
    "    fixtures = fixtures.drop_duplicates(subset=['element', 'kickoff_time'], keep = 'last')\n",
    "    \n",
    "    #make a dictionary using the team ids and team names, and then use that dictionary to fill in the 'team_opponent' col\n",
    "    # with an intelligible name\n",
    "\n",
    "    team_dict = dict(zip(teams_df.id,teams_df.name))\n",
    "    fixtures.loc[fixtures.is_home == True, 'opponent_team'] = fixtures.loc[fixtures.is_home == True, 'team_a'].replace(team_dict)\n",
    "    fixtures.loc[fixtures.is_home == False, 'opponent_team'] = fixtures.loc[fixtures.is_home == False, 'team_h'].replace(team_dict)\n",
    "    \n",
    "    #drop columns we no longer need\n",
    "    fixtures = fixtures.drop(columns=['team_h', 'team_a', 'event_name'])\n",
    "    \n",
    "    return fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unplayed_fixtures = prep_unplayed_fixtures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unplayed_fixtures(df):\n",
    "    #add col to df column to indicate these games have been played -- will be helpful for when i merge unplayed games\n",
    "    df['finished'] = True\n",
    "    \n",
    "    #if a team has completed one game of a double gameweek, the api is pulling both games as having been played, which \n",
    "    #reset the 'finished' labels to make them correct\n",
    "    df['kickoff_time'] = pd.to_datetime(df['kickoff_time'])\n",
    "    df['finished'] = df.kickoff_time < pd.Timestamp.utcnow()\n",
    "    \n",
    "    df = df[df['finished'] == True]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_unplayed_fixtures(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_redundant_cols(df):\n",
    "    df = df.drop(columns = ['id_x', 'id_y'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_redundant_cols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True) #reset indices -- some duplicates occur when appending\n",
    "df.to_pickle('/Users/andrewpeters/GitHub/fpl/data/interim/df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unplayed_fixtures = unplayed_fixtures.reset_index(drop=True)\n",
    "unplayed_fixtures.to_pickle('/Users/andrewpeters/GitHub/fpl/data/interim/unplayed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
