{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from tqdm import tqdm #progress bar library -- not necessary, but helpful since some of this is slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 150)\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I spent a long time cleaning & concatenating data from different seasons until I stumbled upon this:\n",
    "# https://github.com/solpaul/fpl-prediction/blob/master/data/train_v5.csv\n",
    "# this df has data from all seasons since 16-17 by gameweek, with the 19-20 season labeled as 1920, for example, in the \"season\" col\n",
    "# thanks solpaul!\n",
    "\n",
    "# the only thing this dataset is missing is player value on fpl, but from previous analyis, player value wasn't\n",
    "# an effictive predicting feature, so I'm not worried about it for now. Can always merge it later\n",
    "\n",
    "def get_previous_seasons_data():\n",
    "    previous_seasons_data_url = '/Users/andrewpeters/GitHub/fpl/data/external/solpaul-train_v5-311220.csv' #date-code for last time I downloaded this df\n",
    "    previous_seasons_data = pd.read_csv(previous_seasons_data_url, index_col = 0)\n",
    "    \n",
    "    #this dataset has some data from the current (20-21) season, which we don't want\n",
    "    previous_seasons_data = previous_seasons_data[previous_seasons_data.season != 2021]\n",
    "    return previous_seasons_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_data():\n",
    "    #first, pull the ids for all players\n",
    "    url = 'https://fantasy.premierleague.com/api/bootstrap-static/'\n",
    "    r = requests.get(url)\n",
    "    json = r.json()\n",
    "    elements_df = pd.DataFrame(json['elements']) #probably a more efficient way to this than a df\n",
    "    \n",
    "    #using the player ids from elements_df, pull in detailed player info\n",
    "    # I'm going compile two dataframes -- one that shows gw by gw history for each player (this season), and \n",
    "    # another that shows games to be played\n",
    "    history_df = pd.DataFrame()\n",
    "    fixtures_df = pd.DataFrame()\n",
    "\n",
    "    for player in tqdm(elements_df.id):\n",
    "        url = f'https://fantasy.premierleague.com/api/element-summary/{player}/'\n",
    "        r = requests.get(url)\n",
    "        json = r.json()\n",
    "        player_history_df = pd.DataFrame(json['history'])\n",
    "        player_fixtures_df = pd.DataFrame(json['fixtures'])\n",
    "        player_fixtures_df.loc[:, 'element'] = player\n",
    "        history_df = history_df.append(player_history_df)\n",
    "        fixtures_df = fixtures_df.append(player_fixtures_df)\n",
    "    \n",
    "    return history_df, fixtures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_season_df = get_previous_seasons_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 670/670 [01:52<00:00,  5.95it/s]\n"
     ]
    }
   ],
   "source": [
    "current_season_df, unplayed_fixtures_df = get_latest_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump data to /raw folder for safekeeping if api breaks\n",
    "current_season_df.to_pickle('/Users/andrewpeters/GitHub/fpl/data/raw/current_season_df.pkl')\n",
    "unplayed_fixtures_df.to_pickle('/Users/andrewpeters/GitHub/fpl/data/raw/unplayed_fixtures_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_info():\n",
    "    url = 'https://fantasy.premierleague.com/api/bootstrap-static/'\n",
    "    r = requests.get(url)\n",
    "    json = r.json()\n",
    "\n",
    "    #pull player info\n",
    "    elements_df = pd.DataFrame(json['elements'])\n",
    "    elements_df['player'] = elements_df['first_name'] + '_' + elements_df['second_name']\n",
    "    elements_df = elements_df.loc[:, ['id', 'element_type', 'team_code', 'player', 'chance_of_playing_this_round']]\n",
    "    \n",
    "    #merge in team names\n",
    "    teams_df = pd.DataFrame(json['teams'])\n",
    "    elements_df = elements_df.merge(teams_df[['code', 'name']], left_on = 'team_code', right_on='code')\n",
    "    \n",
    "    return elements_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_historical_current_df():\n",
    "\n",
    "    # merge in some of the basic player info from the elements df\n",
    "    merged_current_season_df = current_season_df.merge(elements_df, left_on = 'element', right_on = 'id')\n",
    "    merged_current_season_df = merged_current_season_df.rename(columns={'element_type': 'position',\n",
    "                                     'round': 'gw',\n",
    "                                      'name': 'team',\n",
    "                                      'chance_of_playing_this_round': 'play_proba'\n",
    "                                     })\n",
    "    merged_current_season_df['season'] = 2021\n",
    "    \n",
    "    #add in opp team names\n",
    "    merged_current_season_df = merged_current_season_df.merge(teams_df[['id', 'name']], left_on = 'opponent_team', right_on = 'id')\n",
    "    merged_current_season_df['opponent_team'] = merged_current_season_df['name']\n",
    "\n",
    "    #append the newly merged current season df with the previous season\n",
    "    df = merged_current_season_df.append(previous_season_df)\n",
    "    \n",
    "    #drop columns that only were in one df or the other prior to appending, and that we're not going to use\n",
    "    df = df.drop(columns=['fixture', 'value', 'team_code', 'code', 'relative_market_value_team',\n",
    "            'relative_market_value_opponent_team', 'relative_market_value_team_season',\n",
    "            'relative_market_value_opponent_team_season', 'name'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_df = get_player_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = append_historical_current_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_unplayed_fixtures():\n",
    "    #only need to keep some columns\n",
    "    fixtures = unplayed_fixtures_df[['element', 'team_h', 'team_a', 'event_name', 'kickoff_time', 'finished', 'is_home']]\n",
    "    \n",
    "    #games far enough in the future don't have a date assigned, not useful\n",
    "    fixtures = fixtures.dropna()\n",
    "    \n",
    "    #helper function for stripping letters from gameweek column\n",
    "    def strip_letters(string):\n",
    "        return re.sub('\\D', '', string)\n",
    "    \n",
    "    # convert 'Gameweek 25' to just '25' (as an int)\n",
    "    fixtures.loc[:, 'gw'] = fixtures.apply(lambda x: strip_letters(x['event_name']), axis=1)\n",
    "    \n",
    "    #bring in player-level info to each unplayed fixture row\n",
    "    fixtures = fixtures.merge(df[['element', 'player', 'position', 'team']], how='left', on='element')\n",
    "    \n",
    "    #the merge causes many duplicates, because each player has many rows in df\n",
    "    fixtures = fixtures.drop_duplicates(subset=['element', 'kickoff_time'], keep = 'last')\n",
    "    \n",
    "    #make a dictionary using the team ids and team names, and then use that dictionary to fill in the 'team_opponent' col\n",
    "    # with an intelligible name\n",
    "\n",
    "    team_dict = dict(zip(teams_df.id,teams_df.name))\n",
    "    fixtures.loc[fixtures.is_home == True, 'opponent_team'] = fixtures.loc[fixtures.is_home == True, 'team_a'].replace(team_dict)\n",
    "    fixtures.loc[fixtures.is_home == False, 'opponent_team'] = fixtures.loc[fixtures.is_home == False, 'team_h'].replace(team_dict)\n",
    "    \n",
    "    #drop columns we no longer need\n",
    "    fixtures = fixtures.drop(columns=['team_h', 'team_a', 'event_name'])\n",
    "    \n",
    "    return fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "unplayed_fixtures = prep_unplayed_fixtures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unplayed_fixtures(df):\n",
    "    #add col to df column to indicate these games have been played -- will be helpful for when i merge unplayed games\n",
    "    df['finished'] = True\n",
    "    \n",
    "    #if a team has completed one game of a double gameweek, the api is pulling both games as having been played, which \n",
    "    #reset the 'finished' labels to make them correct\n",
    "    df['kickoff_time'] = pd.to_datetime(df['kickoff_time'])\n",
    "    df['finished'] = df.kickoff_time < pd.Timestamp.utcnow()\n",
    "    \n",
    "    df = df[df['finished'] == True]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_unplayed_fixtures(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_redundant_cols(df):\n",
    "    df = df.drop(columns = ['id_x', 'id_y'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['id_x' 'id_y'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-533-216247845911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_redundant_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-532-ed15894612c2>\u001b[0m in \u001b[0;36mclean_redundant_cols\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_redundant_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'id_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'id_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4161\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4162\u001b[0m         \"\"\"\n\u001b[0;32m-> 4163\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4164\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4165\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3885\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3887\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3920\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3921\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5282\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5283\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['id_x' 'id_y'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df = clean_redundant_cols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True) #reset indices -- some duplicates occur when appending\n",
    "df.to_pickle('/Users/andrewpeters/GitHub/fpl/data/interim/df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "unplayed_fixtures = unplayed_fixtures.reset_index(drop=True)\n",
    "unplayed_fixtures.to_pickle('/Users/andrewpeters/GitHub/fpl/data/interim/unplayed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
